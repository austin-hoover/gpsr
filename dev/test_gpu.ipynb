{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch verion: 2.0.1\n",
      "\n",
      "GPU availablability:\n",
      "\n",
      "CUDA (NVIDIA):\t \tFalse\n",
      "MPS (Apple Silicon):\tTrue\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f'PyTorch verion: {torch.__version__}\\n')\n",
    "print('GPU availablability:\\n')\n",
    "print(f'CUDA (NVIDIA):\\t \\t{torch.cuda.is_available()}')\n",
    "print(f'MPS (Apple Silicon):\\t{torch.backends.mps.is_available() }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device('mps')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "\n",
    "print(f'Using device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from torch.profiler import profile, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-06-26 19:55:31 13361:511464 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-06-26 19:55:32 13361:511464 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-06-26 19:55:32 13361:511464 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     aten::conv2d         0.07%     108.000us        80.74%     124.236ms       3.451ms      71.30 Mb           0 b            36  \n",
      "                aten::convolution         0.23%     360.000us        80.66%     124.128ms       3.448ms      71.30 Mb           0 b            36  \n",
      "               aten::_convolution         0.01%      17.000us        80.43%     123.768ms       3.438ms      71.30 Mb      -1.91 Mb            36  \n",
      "                aten::thnn_conv2d         0.25%     380.000us        80.23%     123.463ms       3.430ms      71.30 Mb       1.91 Mb            36  \n",
      "       aten::_slow_conv2d_forward        80.00%     123.108ms        80.17%     123.371ms       3.427ms      71.30 Mb    -281.37 Mb            36  \n",
      "                 aten::batch_norm         0.06%      89.000us        12.91%      19.868ms     551.889us      71.36 Mb           0 b            36  \n",
      "     aten::_batch_norm_impl_index         0.16%     253.000us        12.85%      19.779ms     549.417us      71.36 Mb           0 b            36  \n",
      "          aten::native_batch_norm        12.56%      19.328ms        12.66%      19.485ms     541.250us      71.36 Mb      -1.07 Mb            36  \n",
      "                 aten::max_pool2d         0.00%       4.000us         2.77%       4.257ms       4.257ms      11.48 Mb           0 b             1  \n",
      "    aten::max_pool2d_with_indices         2.76%       4.253ms         2.76%       4.253ms       4.253ms      11.48 Mb      11.48 Mb             1  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 153.881ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CPU profiling\n",
    "\n",
    "model = models.resnet34()\n",
    "inputs = torch.randn(5, 3, 224, 224)\n",
    "model(inputs)\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU],\n",
    "             profile_memory=True, record_shapes=True) as prof:\n",
    "    model(inputs)\n",
    "        \n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS profiling\n",
      "\n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                aten::batch_norm         2.49%     378.000us        44.18%       6.705ms     186.250us           0 b           0 b            36  \n",
      "    aten::_batch_norm_impl_index         3.48%     528.000us        43.99%       6.677ms     185.472us           0 b           0 b            36  \n",
      "         aten::native_batch_norm        43.53%       6.607ms        43.53%       6.607ms     183.528us           0 b           0 b            36  \n",
      "                    aten::conv2d         0.28%      43.000us        19.38%       2.941ms      81.694us           0 b           0 b            36  \n",
      "               aten::convolution         0.41%      62.000us        19.09%       2.898ms      80.500us           0 b           0 b            36  \n",
      "              aten::_convolution         0.93%     141.000us        18.30%       2.777ms      77.139us           0 b           0 b            36  \n",
      "                      aten::add_        18.11%       2.748ms        18.12%       2.750ms      52.885us           0 b           0 b            52  \n",
      "          aten::_mps_convolution        17.62%       2.675ms        17.76%       2.695ms      74.861us           0 b           0 b            36  \n",
      "                     aten::relu_        11.25%       1.707ms        11.25%       1.707ms      51.727us           0 b           0 b            33  \n",
      "                aten::max_pool2d         0.64%      97.000us         0.65%      98.000us      98.000us           0 b           0 b             1  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 15.178ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-06-26 19:55:32 13361:511464 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-06-26 19:55:32 13361:511464 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-06-26 19:55:32 13361:511464 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "# GPU profiling\n",
    "\n",
    "if DEVICE == torch.device('cuda'):\n",
    "    print('CUDA profiling\\n')\n",
    "    \n",
    "    model = models.resnet34().to(DEVICE)\n",
    "    inputs = torch.randn(5, 3, 224, 224).to(DEVICE)\n",
    "    model(inputs)\n",
    "\n",
    "    with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "                 profile_memory=True, record_shapes=True) as prof:\n",
    "        model(inputs)\n",
    "            \n",
    "    print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "\n",
    "elif DEVICE == torch.device('mps'): \n",
    "    print('MPS profiling\\n')\n",
    "\n",
    "    model = models.resnet34().to(DEVICE)\n",
    "    inputs = torch.randn(5, 3, 224, 224).to(DEVICE)\n",
    "    model(inputs)\n",
    "\n",
    "    with profile(activities=[ProfilerActivity.CPU],\n",
    "                 profile_memory=True, record_shapes=True) as prof:\n",
    "        model(inputs)\n",
    "            \n",
    "    print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10)) \n",
    "\n",
    "else: \n",
    "    print('no GPU enabled') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phase_space_reconstruction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
