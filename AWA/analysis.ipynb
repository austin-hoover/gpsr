{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0143cf5d-d8be-4095-8e73-e2e30a6879a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/r/rroussel/.conda/envs/phase_space_reconstruction/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 3, 180, 180])\n",
      "torch.Size([20, 3])\n",
      "torch.Size([180])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchensemble import VotingRegressor, SnapshotEnsembleRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from fitting import create_ensemble, get_data, get_datasets\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "folder = \"\"\n",
    "save_dir = \"alpha_1000_snapshot\"\n",
    "all_k, all_images, bins, xx = get_data(folder)\n",
    "train_dset, test_dset = get_datasets(all_k, all_images, save_dir)\n",
    "\n",
    "bandwidth = torch.tensor(0.0)\n",
    "ensemble = create_ensemble(bins, bandwidth)\n",
    "\n",
    "from torchensemble.utils import io\n",
    "io.load(ensemble, save_dir)\n",
    "ensemble = ensemble\n",
    "ensemble.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6191f79f-3534-44c8-85ae-bf2b4e9ad46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57dbd758-8870-4d22-a85f-af9f9d746017",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ImageDataset' object has no attribute 'indices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_k \u001b[38;5;241m=\u001b[39m all_k[\u001b[43mtrain_dset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m]\n\u001b[1;32m      2\u001b[0m train_k \u001b[38;5;241m=\u001b[39m train_k\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m      4\u001b[0m train_im \u001b[38;5;241m=\u001b[39m all_images[train_dset\u001b[38;5;241m.\u001b[39mindices]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ImageDataset' object has no attribute 'indices'"
     ]
    }
   ],
   "source": [
    "train_k = all_k[train_dset.indices]\n",
    "train_k = train_k.cuda()\n",
    "\n",
    "train_im = all_images[train_dset.indices]\n",
    "train_im = train_im.cpu()\n",
    "\n",
    "test_k = all_k[test_dset.indices]\n",
    "test_k = test_k.cuda()\n",
    "\n",
    "test_im = all_images[test_dset.indices]\n",
    "test_im = test_im.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcd81aa-aa8f-4d1f-a3b2-09c474b7df6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "recompute_images = True\n",
    "with torch.no_grad():\n",
    "    if recompute_images:\n",
    "        dist = torch.distributions.MultivariateNormal(torch.zeros(6), torch.eye(6))\n",
    "        custom_beam = dist.sample([100000]).cuda()\n",
    "\n",
    "        model_pred = torch.cat(\n",
    "            [ensemble[i](all_k[:,:1].cuda())[0].unsqueeze(0) for i in range(len(ensemble))]\n",
    "        )\n",
    "        model_pred = torch.transpose(model_pred.squeeze(dim=2), 0,1)\n",
    "        model_pred = model_pred.cpu().detach()\n",
    "\n",
    "        torch.save(model_pred, \"model_pred_images.pt\")\n",
    "    else:\n",
    "        model_pred = torch.load(\"model_pred_images.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b50dc63-4f7b-4b43-ae90-688fd2a33ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659c253b-a7a0-4ad5-923b-df99c9b1c0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization import compare_images\n",
    "fig = compare_images(xx, all_image[:,0], model_pred[:,0])\n",
    "fig.set_size_inches(8,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c9ff5b-d063-4a11-9803-a5d626d684f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def apply_filter(X):\n",
    "    return X#ndimage.median_filter(X, size=3)\n",
    "\n",
    "fig,ax = plt.subplots(3,1)\n",
    "fig.set_size_inches(8,16)\n",
    "mean = torch.mean(test_pred, dim=1)[0]\n",
    "std = torch.std(test_pred, dim=1)[0]\n",
    "ax[0].imshow(mean, vmax = torch.max(mean))\n",
    "ax[1].imshow(std, vmax = torch.max(mean))\n",
    "ax[2].imshow(test_im[0][0], vmax = torch.max(mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ce08dc-5363-4ef0-bc56-1e3902c49bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare projections\n",
    "from visualization import compare_image_projections\n",
    "\n",
    "fig = compare_image_projections(xx[0].T[0], test_im, test_pred)\n",
    "fig.set_size_inches(16,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0a8f2c-6d33-4cd9-a05c-77e8dfa83083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare projections\n",
    "from visualization import compare_image_projections\n",
    "\n",
    "fig = compare_image_projections(xx[0].T[0], train_im, train_pred)\n",
    "fig.set_size_inches(16,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925677fa-c37a-464c-a705-9db4092b26d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot reconstructed beam dist\n",
    "from visualization import add_projection\n",
    "beams = [ele.beam_generator() for ele in ensemble]\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "#add_projection(ax, \"x\", beams, xx[0].T[0])\n",
    "#add_projection(ax, \"y\", beams, xx[0].T[0])\n",
    "#add_projection(ax, \"px\", beams, xx[0].T[0])\n",
    "#add_projection(ax, \"py\", beams, xx[0].T[0])\n",
    "add_projection(ax, \"z\", beams, xx[0].T[0])\n",
    "add_projection(ax, \"pz\", beams, xx[0].T[0], plot_samples=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1959880f-cbbc-41c5-844d-24080467e33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results from initial_ensemble\n",
    "# get initial set of estimators\n",
    "initial_estimators = []\n",
    "for _ in range(200):\n",
    "    initial_estimators.append(ensemble._make_estimator())\n",
    "\n",
    "initial_estimators = torch.nn.ModuleList(initial_estimators)\n",
    "initial_estimators.load_state_dict(torch.load(\"initial_ensemble.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd399950-8450-4c1c-818a-9689b89f7a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a2fc80-c02a-47d9-87a1-ce8e15705f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot reconstructed beam dist\n",
    "from visualization import add_projection\n",
    "initial_beams = [ele.beam_generator() for ele in initial_estimators]\n",
    "\n",
    "fig,ax = plt.subplots(3,1,sharex=\"all\")\n",
    "fig.set_size_inches(5,10)\n",
    "add_projection(ax[0], \"z\", beams, xx[0].T[0], \"_fit\")\n",
    "add_projection(ax[0], \"z\", initial_beams, xx[0].T[0], \"_initial\")\n",
    "\n",
    "add_projection(ax[1], \"pz\", beams, xx[0].T[0], \"_fit\")\n",
    "add_projection(ax[1], \"pz\", initial_beams, xx[0].T[0], \"_initial\")\n",
    "\n",
    "add_projection(ax[2], \"x\", beams, xx[0].T[0], \"_fit\")\n",
    "add_projection(ax[2], \"x\", initial_beams, xx[0].T[0], \"_initial\")\n",
    "\n",
    "for ele in ax:\n",
    "    ele.legend()\n",
    "fig.savefig(\"entropy.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11201f89-457c-4014-be1f-777de3bdfcdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f633127-8983-4da2-bbda-b6754c0bcd0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
